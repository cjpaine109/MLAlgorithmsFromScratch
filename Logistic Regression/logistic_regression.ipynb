{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "mnist = fetch_openml('mnist_784', as_frame=False)\n",
    "\n",
    "# Get 'X' and 'y'\n",
    "X = mnist.data\n",
    "y = mnist.target\n",
    "\n",
    "# shapes\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  42. 118. 219.\n",
      " 166. 118. 118.   6.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 103. 242. 254. 254.\n",
      " 254. 254. 254.  66.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  18. 232. 254. 254.\n",
      " 254. 254. 254. 238.  70.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 104. 244. 254.\n",
      " 224. 254. 254. 254. 141.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 207. 254.\n",
      " 210. 254. 254. 254.  34.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  84. 206.\n",
      " 254. 254. 254. 254.  41.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  24.\n",
      " 209. 254. 254. 254. 171.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  91. 137.\n",
      " 253. 254. 254. 254. 112.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  40. 214. 250. 254.\n",
      " 254. 254. 254. 254.  34.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  81. 247. 254. 254.\n",
      " 254. 254. 254. 254. 146.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 110. 246. 254.\n",
      " 254. 254. 254. 254. 171.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  73.  89.\n",
      "  89.  93. 240. 254. 171.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   1. 128. 254. 219.  31.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   7. 254. 254. 214.  28.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0. 138. 254. 254. 116.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  19. 177.  90.   0.   0.   0.   0.   0.\n",
      "  25. 240. 254. 254.  34.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 164. 254. 215.  63.  36.   0.  51.  89.\n",
      " 206. 254. 254. 139.   8.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  57. 197. 254. 254. 222. 180. 241. 254.\n",
      " 254. 253. 213.  11.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 140. 105. 254. 254. 254. 254. 254.\n",
      " 254. 236.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   7. 117. 117. 165. 254. 254.\n",
      " 239.  50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "# Look at the data in 'X' -> instance\n",
    "random_image = X[10]\n",
    "y_label = y[10]\n",
    "print(random_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    }
   ],
   "source": [
    "# Display image\n",
    "def show_image(image):\n",
    "    image = image.reshape(28, 28)\n",
    "    plt.imshow(image, cmap='binary')\n",
    "    plt.axis(\"Off\")\n",
    "\n",
    "show_image(random_image)\n",
    "plt.show()\n",
    "print(f\"Label: {y_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Model Score: 89.8014%\n"
     ]
    }
   ],
   "source": [
    "# Simple model - baseline\n",
    "sum_three = sum(random_image)\n",
    "y_three = (y == '3') # boolean array\n",
    "results = []\n",
    "\n",
    "for image in X:\n",
    "    if sum(image) == sum_three:\n",
    "        results.append(True)\n",
    "    else:\n",
    "        results.append(False)\n",
    "\n",
    "# Eval the simple model\n",
    "acc_score = sum(result == label for result, label in zip(results, y_three)) / len(y_three)\n",
    "scaled_score = acc_score * 100\n",
    "print(f\"Simple Model Score: {scaled_score:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our training and testing datasets\n",
    "X = X[:45000]\n",
    "y = y[:45000]\n",
    "y_3 = (y == '3').astype(int)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y_3, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ---> Logistic Regression\n",
    "class LogisticRegressionCustom:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=1000, lambda_=0.01):\n",
    "        self.learning_rate_ = learning_rate\n",
    "        self.num_iterations_ = num_iterations\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def gradient_descent(self, X, y, W):\n",
    "        m = len(y)\n",
    "        for iter in range(self.num_iterations_):\n",
    "            h = self.sigmoid(X @ W)\n",
    "            error = h - y\n",
    "            gradient = X.T @ error / m\n",
    "            reg_term = (self.lambda_ / m) * W\n",
    "            reg_term[0] = 0\n",
    "            W = W - self.learning_rate_ * (gradient + reg_term)\n",
    "        return W\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        self.W = np.zeros(X.shape[1])\n",
    "        self.W = self.gradient_descent(X, y, self.W)\n",
    "        return self.W\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.ones([np.ones((X.shape[0], 1)), X])\n",
    "        return self.sigmoid(X @ self.W) >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test our model\n",
    "log_reg = LogisticRegressionCustom()\n",
    "weights = log_reg.fit(X_train, y_train)\n",
    "predictions = log_reg.predict(X_test)\n",
    "\n",
    "# Eval model\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "scaled_score = acc_score * 100\n",
    "print(f\"Custom Model Results: {scaled_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
